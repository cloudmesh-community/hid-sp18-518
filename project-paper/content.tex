% status: 40
% chapter: Virtual Machines
% 
\title{Leveraging REST for cloud portability}

\author{Harshad Pitkar}
\affiliation{%
  \institution{Indiana University}
  \city{Bloomington} 
  \state{IN} 
  \postcode{47408}
  \country{USA}}
\email{hpitkar@iu.edu}

\author{Sushant Athaley}
\affiliation{%
  \institution{Indiana University}
  \streetaddress{Smith Research Center}
  \city{Bloomington} 
  \state{IN} 
  \postcode{47408}
  \country{USA}}
\email{sathaley@iu.edu}

\author{Michael Robinson}
\affiliation{%
  \institution{Indiana University}
  \city{Bloomington} 
  \state{IN} 
  \postcode{47408}
  \country{USA}}
\email{micbrobi@iu.edu}


% The default list of authors is too long for headers}
\renewcommand{\shortauthors}{H. Pitkar, S. Athaley, M. Robinson}


\begin{abstract}
Our research measures how the portability of an application is impacted by
decisions made early in the software lifecycle when native cloud provider APIs
are used. We demonstrate how efforts to leverage scalable, reproducable
solutions like boto and libcloud are advantageous. We derived reproducable code
using Swagger and Python to show how libraries like boto and libcloud can be 
used to migrate an application from one cloud provider to another with a
measurable reduction in human error and with less  time to execute.
Additionally, we leveraged Swagger to develop RESTful APIs to  further improve
the gains. We captured the results of the research to share the derived code and
concluded how the research can be applied to existing and new development
efforts intending to leverage cloud providers. 
\end{abstract}

\keywords{hid-sp18-518, hid-sp18-517, hid-sp18-402, libcloud, boto}

\maketitle

\section{Introduction}\label{introduction}

Cloud portability is a growing area of research due to the increased
profiliferation of cloud providers~\cite{hid-sp18-518-Cloud-Council}. Each
provider has unique APIs and tools to their cloud environments  which can
disincentivize portability as it influences a consumer to stay with their
existing solution provider. Efforts to standardize cloud portability like TOSCA
have made progress yet participation by cloud providers is constrained due to
the competitive nature in the space. Each cloud provider is looking to retain
their userbase and there is also a desire by each provider to become the de
facto standard by being the market leader. To fill the gap, solutions like
Apache libcloud and boto have delivered an abstraction solution to developers to
design applications that are easy to port.

Developers are already confronted with a lack of transparency on which cloud
provider is optimal for the long-term sustainability of their application.
Additionally, attempts to abstract away from cloud providers are helpful yet
their non-standardization still potentially locks you into the solutions
provided by Apache or communities like boto. We will deliver a continuation of
that abstraction concept with an accepted standard, REST, to extend libcloud and
boto. By leveraging REST, we introduced a standardized implementation
that leverages cloud portability libraries to manage the diversity of cloud
applications. A high-level abstract of the concept is shown in
Figure~\ref{F:arch}.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\columnwidth]{images/proj-arch.pdf}
  \caption{Project Architecture}\label{F:arch}
\end{figure}

\section{Technology Review}

The National Institute of Standards and Technology defines cloud  portability as
``data that can be moved from one cloud system to another and that  applications
can be ported and run on different  cloud systems at an  acceptable
cost.''~\cite{hid-sp18-518-NIST-291} The concept of portability can be extended
to encompass the full application stack from the web service to the underlying
hardware itself. Portability can also simply mean the ability to ensure high
availability where you only are looking to protect against one cloud provider
being a single point of faiure.

In NIST Special Publication 500-293, the United States governement has defined a
strategic roadmap that includes ten formal recommendations for all cloud usage.
Out of the ten requirements, eight of them reference portability and
interoperability. The Standards Acceleration to Jumpstart the Adoption of Cloud
Computing (SAJACC) is an initiative under the guidance of NIST 500-293 that is
to define ``qualitative testing of specifications against interoperability,
security, and portability requirements.''~\cite{hid-sp18-518-NIST-293}

To define portability further, we have to differentiate the tiers of cloud
service and where portability may be needed. Cloud providers have generally
grouped service into the following four types.

\begin{itemize}
\item
  Infrastructure as a Service - IaaS
\item
  Platform as a Service - PaaS
\item
  Software as a Service - SaaS
\item
  Functions as a Service - FaaS
\end{itemize}

Each grouping has dependencies that can make portability more difficult. For
example, AWS Lambda, which is a FaaS solution, is highly specialized and the
APIs in use are specific to that vendor. While solutions like libcloud and boto
attempt to include all providers, the speed of the market makes it challenging
for portability libraries to include the latest and great cloud provider
offerings~\cite{hid-sp18-518-LibCloud}. Another dependency is the complexity of
what needs to be ported. IaaS is the closest cloud offering to bare-metal and
dependencies for hardware-specific requirements are not a consideration for most
portability offerings. As the adoption of containers and functions increases,
legacy implementations of cloud solutions that leveraged IaaS will be more
difficult to port over. 

The work by the Irish Centre for Cloud Computing provided a ``qualitative
comparative of current  open-source  IaaS frameworks'' which is in contrast to
vendor offerings which tend to lack in
portability~\cite{hid-sp18-518-Comp-study}. The study was limited to the five
top open-source providers of IaaS and the derived outcome of the comparison was
a breakdown over twenty categories that included portability to vendor IaaS. The
summary was that each solution is tailored towards a specific need and while
portability is possible, there are other challenges that are considered when
choosing when and which of many cloud providers you will end up using.

The research by Kostoska, Gusev and Ristov further highlights the
challenges with portability, open-source and standards. The
researchers were ``motivated by several open research questions about
cloud solutions, such as how to wisely choose a cloud host for
services and how to change the cloud provider in an easy
manner.''\cite{hid-sp18-518-Kostoska-Gusev-Ristov} The paper
stipulates that not only is it difficult to choose which cloud
provider to use but that the community of cloud providers and what
differentiates them continues to grow. The work concludes that no
standard exists and their own efforts are only to ``offer a
possibility for a documented service exchange.''

An interesting example of where multiple private sector providers can ensure
interoperability is illustrated by Wired journalist Joe Weinman. In his
writings, he expresses how air travel is easy for a consumer to determine where
to fly out of, how to get through security, and to have confidence their bags
will arrive. The history of aviation is one of consolidation and resistance to
standards yet the market ultimately did accept some level of
standardization.~\cite{hid-sp18-518-Wired} Weinman concludes with ``The Internet
took decades to go from a vision of packet switching to where it is today. 
Between the IEEE, industry, and academia, one can hope that the vision of an
Intercloud is now getting the attention it deserves.''

In summary, multiple efforts by government and academia are encouraging
standardization. For cloud providers to capture the market opportunity of
Federal, State and local institutions, they will be encouraged to comply with
the newly developed standards. The counter is that private sector will continue
to encourage specialization and consumer demand continues to show exponential
growth. As Weinman states, the Internet is now a blend of decades of
collaboration, incentives and mistakes and cloud portability will likely be the
same.

\section{Background on LibCloud}

The concept of LibCloud began in 2009 to address the growing challenge of API
diversity between the dozens of cloud providers. The effort eventually became a
top level Apache project in 2011. LicCloud provides support for the three Cloud
providers we tested, Amazon Web Services, Microsoft Azure and Google Cloud and
also supports dozens more.

The solution breaks down support between seven primary aspects, which are
Compute, Storage, Key Pair Management, Load Balancing, Container, Backups, and
DNS. The support for each aspect varies depending on the native support by the
provider and the project status. Another important consideration is region
support which is typically restrained to the primary region. This may limit the
usefulness for projects that leverage cloud resources globally.

Each aspect has a varying degree of functions available that also may not be
fully available to leverage. For example, the supported methods for Compute are
fully implemented for EC2 and Azure Virtual Machines yet the deploy node method
is not yet available for Google Compute Engine. An example that demonstrates the
challenge with migrating to a newer service provider is key management. Amazon
EC2 fully supports all methods for key management yet Azure and Google Cloud
Engine do not support even one.

Another challenge is that each cloud provider does not offer a testing platform
for the use of LibCloud. To test the use of the APIs, you will have to leverage
production services to determine the solution works. We leveraged free trials to
develop the use of libcloud which is suboptimatal for long-term development.

\section{Background on Boto3}

Boto3 is the underlying technology that powers the command line interface for
AWS. It is a software development kit that is freely available for customized
use if you wish to have raw access to the AWS cloud APIs. Underneath boto3 is
botocore, which is a framework that can be used to extend into other cloud
providers. The concept of a Python SDK for managing cloud services provided in
AWS began by Mitch Garnatt in 2006 and has grown exponentially
since.~\cite{hid-sp18-518-AWS-boto3}

Botocore itself is driven by JSON blobs that define the feature and its use.
This concept makes it easy to integrate into other coding languages and also
makes the platform simple to extend. The native instance of boto groups the
available features into resources, collections, clients, paginators and waiters.
The features in resources and collections are the core tools that allow you to
manipulate and enumerate cloud resources. The other three feature groups are for
ease of use for aspects like session management and grouping of
data.~\cite{hid-sp18-518-Boto3}

Boto3 strengths also lead to some of its limitations. The library grants
in-depth ability to manage AWS resources and is a mature offering that stays
current with the rapid pace of AWS feature releases. While AWS features are
provided into boto3 for AWS customers, the extensions into other cloud providers
is more limited as they are community-driven. This has created a situation where
boto3 is more likely to be used solely for AWS.

\section{Architecture}

The summary of technologies used were implemented as scripts or markups to
leverage multiple methods available in libcloud and boto3. The solution was
optimized to provide a turnkey implementation to easily manage the deployment
and interaction with resources in three of the primary cloud providers. The
summation is a deployable Swagger instance that provides a RESTful API to use
the underlying python scripts which use libcloud and boto3 to interact, all with
little to no knowledge required by the user.

Since this is a webservice, it provides a capability to access it
programmatically which is advantageous as multiple VMs can be created within a
few minutes as compared to manually creating through AWS console which is
time-consuming if we have to do it in mass. It was helpful also when there is a
desire to create VMs with the same configuration for multiple users as this
webservice can be invoked through any program. Default VM configuration can be
used during creation of a VM and avoid defining configuration for each. It also
simplifies start, stop and termination of all VMs as a list of VMs can be
provided for iteration through that list to perform the desired operation. 
Since it is configuration driven through automation, human error was minimized.
Our service provided flexibility to work with different clouds (currently 3) and
scalability to add more cloud implementations. Service will encapsulate various
cloud implementations regardless of their operating difference and provides a
one-stop solution.

\section{Other technologies used}
The other technologies leveraged for implementation are listed below. The
solution leverages these technologies yet the paper does not describe their
use in detail.

\begin{description}

\item{\bf Python.} Python was the underlying language that was used to bridge
the use of libcloud and boto into the Swagger platform. Multiple scripts were
written in python that would handle credential handling to the methods that
would interact with Compute or Storage resources.
\item{\bf Swagger.} Swagger and Swagger Codegen was used to generate the
documentation and design to enable a RESTful API implementation of the python
scripts. Swagger was leveraged to implement the REST interfaces to
align with course content. There are other frameworks available such as Flask or
Django that were not assessed.
\item{\bf Amazon Web Services.} AWS natively supports boto3 which provided
robust options on what could be delivered via REST. Also, as AWS is the industry
leader, there is significant open-source development available that provided
examples of how to use libcloud and boto3.
\item{\bf Google Cloud.} GCE has an in-depth integration available with
libcloud and Apache provides very detailed examples on how to use libcloud.
\item{\bf Microsoft Azure.} Azure is not natively supported by libcloud or boto3
yet libcloud has extensive support for most of the available API calls.

\end{description}

\section{Methodology}

Python libraries exist now that help you abstract your project from  your cloud
provider. This may be important if you think you may need to use multiple cloud
providers or if you want to ensure you take steps to avoid provider lock-in.
There are multiple providers in this space and one of them is Apache
Libcloud~\cite{hid-sp18-518-LibCloud} To put it simply, this library allows you
to code simple resource  management that is independent of cloud provider
specific API calls.

Our research is intended to prove that their is significant value to leveraging
frameworks that provide portability. By comparing the native porting of an
application to a defined RESTful API, we theorize the porting of a service
between cloud providers will be more efficient. The combination of open-source
portability python libraries, the speed of Swagger, and the standardization of
REST will be a combination that will drastically improve portability.

The Cloud Security Council has broken cloud portability into five measurable
aspects of instruction, syntactic, metadata, behavior and policy. We will
leverage the instruction aspect, where the correct application instructions are
followed when ported, and the syntactic facet where porting between providers is
transparent to the end user. This implies our testing is more closely aligned
with real-world adoption but assumes aspects like policy are left
unattended.~\cite{hid-sp18-518-Cloud-Council}

The instruction facet looks to assess whether the intended target that is being
ported to is capable of ``understanding and executing the instructions contained
in the executable artifacts of the
application.''~\cite{hid-sp18-518-Cloud-Council} This is a strong consideration
if you are running code that depends on an underlying runtime environment,
especially if it depends on a specific environment such as the difference
between Java Runtime 7 or 8. When the porting is poorly executed, it may result
in execution failures, poor performance or even worse, the instruction appears
to run yet gives inaccurate results that must be found by regression testing.

The syntactic element looks to identify the ease of the solution to alleviate
knowledge of the underlying syntax for the cloud provider API or needing to
manually convert different unit sizes. This is salient when providers may use
custom naming conventions or if the cloud provider expects steps to be executed
in a specific fashion. This is also important at higher abstraction layers such
as the application data itself, where the ``PaaS service may provide instances
of databases ready-to-use, in which case the actual databases provided may be
sensitive to the data syntax of the customer
data.''~\cite{hid-sp18-518-Cloud-Council} The syntactic element is also where we
will highlight issues for cross-platform support in instances where the target
provider either does not have API support or libcloud does not support yet.

\section{Benchmarking}

To experiment, we leveraged the following resources.

\begin{itemize}

\item Swagger development to design/build API services for UI
\item Python development to leverage libcloud
\item Amazon Web Services, Azure, and Google Cloud
\item Swagger API documentation
 
\end{itemize}


To reflect on the three cloud providers chosen, the results were expected to
skew towards the strengths and weaknesses of each provider. AWS is considered
the most mature provider with a very deep API offering where solutions like
Azure are making progress. Alternatively, Data Motion states ``Google developed
the Kubernetes standard that AWS and Azure now offer and GCP specializes in high
compute offerings like Big Data, analytics and machine
learning.''\cite{hid-sp18-518-DataMotion}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=\columnwidth]{images/aws-azure-google.pdf}
  \caption{Provider Comparison}\label{F:comparison}
\end{figure}

To determine the effectiveness, we have chosen to measure the cycle time on
porting a solution without libcloud to two alternatives, leveraging native
libcloud only and then our RESTful implementation of libcloud. Additionally, we
will measure the lead time metrics on using a RESTful API compared to the
command line python libraries to determine if removing the expectation for
portability can improve application development speed.

\subsection{Benchmarking of libcloud library with Python}

To use the libcloud library in your python environment, you install the
apache-libcloud package using the Python package management system, pip.
Libcloud currently supports Python versions 2.5, 2.6, 2.7 and Python 3. To use
libcloud as a library, leverage Python and import libcloud like any other
library. A useful feature to use in Python is the help function which will
provide you a simple manual on further use of libcloud.

As an example, we leveraged libcloud to configure and manage EC2 in AWS. We
first needed to configure credentials for an active cloud provider account and
then configured libcloud provider to use that account. To be able to access AWS
S3 from libcloud, we need the access key to be specified in the call. An access
key can be setup on AWS console by navigating to My Security credentials,
Encryption Keys, and then Access Keys.Next, local variables were defined to
store the credentials to be used. Once that was set up, we defined the EC2 
driver with our region preference, which was AWS us-east-1, the most full
featured region. This is because there are additional tasks that must be taken
with SSH keys. We used our browser to review EC2 and finalize the setup.

A Python example for leveraging libcloud to list available containers in an AWS
S3 instance is shown below. The key steps are importing the libraries and
leveraging the functions that enable connectivity, authentication and
authorization. Once that is complete, you can pull or push information using the
family of functions that are available in Libcloud for your flavor of cloud
provider, in this instance which is AWS.



\begin{figure}[htb]

\begin{verbatim}

from libcloud.storage.types import Provider
from libcloud.storage.providers import get_driver


cls = get_driver(Provider.S3_US_EAST2)
driver = cls('api key', 'api secret key')

d = driver.list_containers();

print d;

\end{verbatim}

\caption{Leveraging Libcloud
~\cite{hid-sp18-518-LibCloud}}\label{c:libcloud-example}

\end{figure}

The following table is a breakdown of other functions that were leveraged in
Libcloud during our development. The list is tailored towards only what we used
directly. If a feature is specific towards a certain cloud provider, as in it
was not completely abstracted by Libcloud, the description will point out the
customized use.
 
\begin{table}[]
\centering
\caption{LibCloud features leveraged}\label{t:libcloud-table}
\resizebox{\textwidth}{!}{%
\begin{tabular}{lll}
 \toprule
 \multicolumn{3}{|c|}{Features} \\
 \midrule
Function & Description & Command\\
 \midrule
 Driver	& How to choose the primary cloud provider that will be used by
following functions	& \verb|libcloud.get\_driver()|\\
 DNS & Used to configure DNS for compute resources & \verb|dns()|\\
 Load Balancing & Used to configure load balancing for compute resources &
\verb|get\_driver\_lb()|\\
 Node listing & Used to enumerate the nodes already created within the cloud
provider & \verb|list\_nodes()|\\
 Size listing & Used to enumerate the size of the VM and supporting components &
\verb|list\_sizes()|\\
 Image listing & Used to enumerate the avaiable, deployable images the cloud
provider makes available & \verb|list\_images()|\\
 Get Image ID & Used to pull the unique identifier for the human-readable name
for the chosen image & \verb|get\_image()|\\
 Get Node ID & Used to pull the unique identifier for one or many VMs &
\verb|ex\_get\_node()|\\
 Create new node & Used in conjuection with image listing to deploy a new VM &
\verb|create\_node()|\\
 Start a node & Used to tell a previously built VM to boot &
\verb|ex\_start\_node()|\\
 Stop a node & Used to direct a VM to begin shutdown gracefully &
\verb|ex\_stop\_node()|\\
 Destroy a node & Used to delete a VM and will return success &
\verb|destroy\_node()|\\
 Get Volume ID & Used to enumerate the unique identifier for cloud storage
typically used by a VM & \verb|ex\_get\_volume()|\\
 Create new volume & Used to add addtional storage to a VM &
\verb|create\_volume()|\\
 Create new snapshot & Used to take a recovery image of a VM for restoration
purposes & \verb|create\_volume\_snapshot()|\\
 Destroy a volume or snapshot & Used to delete storage or snapshot to recover
storage space & \verb|destroy\_volume()|\\
  \bottomrule
 \end{tabular}%
 }
 \end{table}

\subsection{Benchmarking of boto3 library with Python}

In order to leverage boto3 within a python console, you simply can install using
pip like we have done with libcloud. Boto3 was developed with Python 3 in mind
yet backwards compatibility is available to Python 2.7 and 2.6.5. A salient
point to stress is that boto3 is different than boto, like how Python 2 is
different than Python 3. The authors of boto stress that boto3 should be used as
boto is only supported for older implementations. The features are similar yet
boto will eventually be deprecated and developers will have to migrate to
boto3.~\cite{hid-sp18-518-AWS-boto3}

As with all interactions with cloud providers, the aspect of credentials and
privileges must be addressed before successful use of the libraries. Since boto3
powers the use of the AWS CLI, we found the use of the AWS CLI to be the most
effective way to configure credentials. The credential space is shared between
boto3 and AWS CLI and there is less error when using the user-friendly AWS CLI.
Credentials can be hardcoded as well and examples are provided by
Amazon.~\cite{hid-sp18-518-Boto3} The last step that must be taken is define the
location you wish boto3 to focus on such as AWS regions. Multi-region support is
limited and if you do not define an alternate region, it will use us-east-1.

Below is an example of how we leveraged boto3 to start and stop an instance
defined in AWS EC2. The python script is passed two parameters, On or Off, and
the instance ID you wish to change. The parameters are ultimately passed to
boto3 to connect to your EC2 instances and perform the action.

\begin{figure}[htb]

\begin{verbatim}

# To start the instance
$ python boto_ec2.py <on> <instance id>

# To stop the instance
$ python boto_ec2.py <off> <instance id>

# Add below code to a file named boto_ec2.py
# 
# Code developed in support from the online documentation
# http://boto3.readthedocs.io/en/latest/guide/ec2-example-managing-instances.
# html
# 
import sys
import boto3
from botocore.exceptions import ClientError

instance_id = sys.argv[2]
action = sys.argv[1].upper()

ec2 = boto3.client('ec2')

if action == 'ON':
    # Do a dryrun first to verify permissions
    try:
        ec2.start_instances(InstanceIds=[instance_id], DryRun=True)
    except ClientError as e:
        if 'DryRunOperation' not in str(e):
            raise

    # Dry run succeeded, run start_instances without dryrun
    try:
        response = ec2.start_instances(InstanceIds=[instance_id], DryRun=False)
        print(response)
    except ClientError as e:
        print(e)
else:
    # Do a dryrun first to verify permissions
    try:
        ec2.stop_instances(InstanceIds=[instance_id], DryRun=True)
    except ClientError as e:
        if 'DryRunOperation' not in str(e):
            raise

    # Dry run succeeded, call stop_instances without dryrun
    try:
        response = ec2.stop_instances(InstanceIds=[instance_id], DryRun=False)
        print(response)
    except ClientError as e:
        print(e)

\end{verbatim}

\caption{Leveraging Boto3~\cite{hid-sp18-518-Boto3}}\label{c:boto3-example}

\end{figure}

Once boto3 is imported, the object ec2 is leveraged for ease of use. The client
method is defined with the intended cloud provider environment, in this case it
is AWS EC2. The calls in Python using the variable are then vendor agnostic. For
the methods for starting and stopping instances, boto3 allows the author to
follow a common syntax structure that will map the parameters into the
underlying vendor API calls. Last, boto3 will capture the returned output
provided by the vendor and will make it available for your use. In this python
script, we have captured the response into a variable for later use and to show
that it works as defined, the output is sent to the console.

\section{Use Case: Rest API calls}

\begin{figure}[htb]

The final outcome of the code development was an ability to leverage an HTTP
call to request usage of cloud services. For example, below is a sample of an
API call where elements are passed with POST to provide the parameters needed
for libcloud or boto to initiate the call. When the call is completed, the API
returns a string on what was requests. The parameters are sent in JSON format
and are extensible into other platforms. Some feature enhancements for the REST
API call would be error handling if libcloud or boto have issues executing the
call.  

\begin{verbatim}
curl -X POST "http://localhost:8080/cloudmesh/compute/aws/ec2" -H  "accept:
application/json" -H  "Content-Type: application/json" -d "{  \"vmId\": \"NA\", 
\"name\": \"myVM\",  \"image\": \"ami-25615740\",  \"region\": \"us-east-2\", 
\"size\": \"t2.micro\",  \"status\": \"NA\"}"
\end{verbatim}

\caption{REST API call example}\label{c:REST-example}
\end{figure}


By leveraging an HTTP call allows, we have created an opportunity to extend the
solution for automation or to provide a browser-based user experience. Both of
those types of solutions would improve the scalability of what can be done
compared to cloud provider UI or the provided command-line tools. Both solutions
are also less prone to error by incorrect data entry or mistakes by overly broad
permissions. 



\section{Results}
Review the code developed


Comparison of command line tools to Python libraries libcloud and boto3

\section{Summary}

\section{Artifacts}

\begin{acks}

  The authors would like to thank Dr.~Gregor~von~Laszewski for his
  support and suggestions to write this paper.

\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 

